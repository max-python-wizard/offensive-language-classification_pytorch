{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/byun/extra/miniconda/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sprawdzanie czy w systemie jest karta graficzna Nvidia - CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_av = torch.cuda.is_available()\n",
    "cuda_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if cuda_av:\n",
    "    cuda_id = torch.cuda.current_device()\n",
    "    print(f'ID urządzenia CUDA: {cuda_id}')\n",
    "    print(f\"Nazwa urządzenia CUDA: {torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tworzenie kodu uniwersalnego: dla CUDA i CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ładowanie danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('data/olid-training-v1.0.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_a  \\\n",
       "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets = tweets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets = tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### usuwanie tweetow gdzie kulumna subtask_b jest nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.dropna(subset=['subtask_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4400"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tokenizacja, lematyzacja, usówanie pewnych słów\n",
    "liczenie najdłuższego przetworzonego tweeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dodawanie kolumny z tokenami\n",
    "tweets['tokens'] = tweets['tweet'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(@USER, She, should, ask, a, few, native, Amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>(@USER, @USER, Go, home, you, ’re, drunk, !, !...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(@USER, Someone, should'veTaken, \", this, piec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97670</td>\n",
       "      <td>@USER Liberals are all Kookoo !!!</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "      <td>(@USER, Liberals, are, all, Kookoo, !, !, !)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>77444</td>\n",
       "      <td>@USER @USER Oh noes! Tough shit.</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(@USER, @USER, Oh, noes, !, Tough, shit, .)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_a  \\\n",
       "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "5  97670                  @USER Liberals are all Kookoo !!!       OFF   \n",
       "6  77444                   @USER @USER Oh noes! Tough shit.       OFF   \n",
       "\n",
       "  subtask_b subtask_c                                             tokens  \n",
       "0       UNT       NaN  (@USER, She, should, ask, a, few, native, Amer...  \n",
       "1       TIN       IND  (@USER, @USER, Go, home, you, ’re, drunk, !, !...  \n",
       "3       UNT       NaN  (@USER, Someone, should'veTaken, \", this, piec...  \n",
       "5       TIN       OTH       (@USER, Liberals, are, all, Kookoo, !, !, !)  \n",
       "6       UNT       NaN        (@USER, @USER, Oh, noes, !, Tough, shit, .)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dodawanie kolumny z lematami za pomoca funkcji lambda - przy tym usuwanie:\n",
    "# odwolan do wczesniejszych tweetow (zawiera @)\n",
    "# - slowa url (czyli adresy stron inernetowych które w danych wejściowych mają URL zamiast adreasu.\n",
    "# # - hasztagów; przyimków i innych częstych słów (stop words) oraz znaków interpunkcyjnych.\n",
    "# spacji ' ', '  ', '   '\n",
    "\n",
    "# emotikony zostawiam - uważam, że też niosą znaczenie\n",
    "\n",
    "tweets['lemmas'] = tweets['tokens'].apply\\\n",
    "    (lambda list_tokens : [token.lemma_.strip() for token in list_tokens if ('@' not in token.lemma_ \\\n",
    "                                                                     and '#' not in token.lemma_ and 'url' not in token.lemma_ \\\n",
    "                                                                     and not token.is_stop and not token.is_punct and token.lemma_ != ' ' \\\n",
    "                                                                     and token.lemma_ != '  ' and token.lemma_ != '   '\n",
    "                                                                     and token.lemma_ != '    ' and token.lemma_.strip() != '')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(@USER, She, should, ask, a, few, native, Amer...</td>\n",
       "      <td>[ask, native, Americans]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>(@USER, @USER, Go, home, you, ’re, drunk, !, !...</td>\n",
       "      <td>[home, drunk, MAGA, Trump2020, 👊, 🇺, 🇸, 👊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(@USER, Someone, should'veTaken, \", this, piec...</td>\n",
       "      <td>[should'vetaken, piece, shit, volcano, 😂]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97670</td>\n",
       "      <td>@USER Liberals are all Kookoo !!!</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "      <td>(@USER, Liberals, are, all, Kookoo, !, !, !)</td>\n",
       "      <td>[liberal, Kookoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>77444</td>\n",
       "      <td>@USER @USER Oh noes! Tough shit.</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(@USER, @USER, Oh, noes, !, Tough, shit, .)</td>\n",
       "      <td>[oh, no, tough, shit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13223</th>\n",
       "      <td>63482</td>\n",
       "      <td>@USER is advocating for conduct within bounds ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>(@USER, is, advocating, for, conduct, within, ...</td>\n",
       "      <td>[advocate, conduct, bound, Human, Rights, terr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>87416</td>\n",
       "      <td>@USER @USER @USER @USER Liars like the Antifa ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>(@USER, @USER, @USER, @USER, Liars, like, the,...</td>\n",
       "      <td>[liar, like, Antifa, twin, vigorously, defend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>95338</td>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>(@USER, Sometimes, I, get, strong, vibes, from...</td>\n",
       "      <td>[strong, vibe, people, man, vibe, ten, million...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>82921</td>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "      <td>(@USER, And, why, report, this, garbage, .,  ,...</td>\n",
       "      <td>[report, garbage, crap]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>27429</td>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(@USER, Pussy)</td>\n",
       "      <td>[Pussy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "5      97670                  @USER Liberals are all Kookoo !!!       OFF   \n",
       "6      77444                   @USER @USER Oh noes! Tough shit.       OFF   \n",
       "...      ...                                                ...       ...   \n",
       "13223  63482  @USER is advocating for conduct within bounds ...       OFF   \n",
       "13227  87416  @USER @USER @USER @USER Liars like the Antifa ...       OFF   \n",
       "13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n",
       "13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n",
       "13238  27429                                        @USER Pussy       OFF   \n",
       "\n",
       "      subtask_b subtask_c                                             tokens  \\\n",
       "0           UNT       NaN  (@USER, She, should, ask, a, few, native, Amer...   \n",
       "1           TIN       IND  (@USER, @USER, Go, home, you, ’re, drunk, !, !...   \n",
       "3           UNT       NaN  (@USER, Someone, should'veTaken, \", this, piec...   \n",
       "5           TIN       OTH       (@USER, Liberals, are, all, Kookoo, !, !, !)   \n",
       "6           UNT       NaN        (@USER, @USER, Oh, noes, !, Tough, shit, .)   \n",
       "...         ...       ...                                                ...   \n",
       "13223       TIN       GRP  (@USER, is, advocating, for, conduct, within, ...   \n",
       "13227       TIN       GRP  (@USER, @USER, @USER, @USER, Liars, like, the,...   \n",
       "13235       TIN       IND  (@USER, Sometimes, I, get, strong, vibes, from...   \n",
       "13237       TIN       OTH  (@USER, And, why, report, this, garbage, .,  ,...   \n",
       "13238       UNT       NaN                                     (@USER, Pussy)   \n",
       "\n",
       "                                                  lemmas  \n",
       "0                               [ask, native, Americans]  \n",
       "1             [home, drunk, MAGA, Trump2020, 👊, 🇺, 🇸, 👊]  \n",
       "3              [should'vetaken, piece, shit, volcano, 😂]  \n",
       "5                                      [liberal, Kookoo]  \n",
       "6                                  [oh, no, tough, shit]  \n",
       "...                                                  ...  \n",
       "13223  [advocate, conduct, bound, Human, Rights, terr...  \n",
       "13227     [liar, like, Antifa, twin, vigorously, defend]  \n",
       "13235  [strong, vibe, people, man, vibe, ten, million...  \n",
       "13237                            [report, garbage, crap]  \n",
       "13238                                            [Pussy]  \n",
       "\n",
       "[4400 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for index, row in tweets.iterrows():\n",
    "#     for word in row['lemmas']:\n",
    "#         if word == '':\n",
    "#             print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets.iloc[499, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if tweets.iloc[500, 6][0] == '':\n",
    "#     print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets.iloc[500, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets.loc[:3,'lemmas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52415</td>\n",
       "      <td>@USER was literally just talking about this lo...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>(@USER, was, literally, just, talking, about, ...</td>\n",
       "      <td>[literally, talk, lol, mass, shooting, like, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13384</td>\n",
       "      <td>@USER Canada doesn’t need another CUCK! We alr...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>(@USER, Canada, does, n’t, need, another, CUCK...</td>\n",
       "      <td>[Canada, need, CUCK, LooneyLeft, Liberals, f**...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28414</td>\n",
       "      <td>@USER you are a lying corrupt traitor!!! Nobod...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>(@USER, you, are, a, lying, corrupt, traitor, ...</td>\n",
       "      <td>[lie, corrupt, traitor, want, hear, anymore, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28195</td>\n",
       "      <td>@USER @USER @USER gun control! That is all the...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "      <td>(@USER, @USER, @USER, gun, control, !, That, i...</td>\n",
       "      <td>[gun, control, kid, ask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>56117</td>\n",
       "      <td>@USER @USER @USER @USER LOL!!!   Throwing the ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>(@USER, @USER, @USER, @USER, LOL, !, !, !,   ,...</td>\n",
       "      <td>[LOL, throw, BULLSHIT, Flag, nonsense, putupor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12681</td>\n",
       "      <td>@USER @USER Kind of like when conservatives wa...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>(@USER, @USER, Kind, of, like, when, conservat...</td>\n",
       "      <td>[kind, like, conservative, wanna, associate, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>82904</td>\n",
       "      <td>@USER @USER Da fuck is going on people?   Ther...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>(@USER, @USER, Da, fuck, is, going, on, people...</td>\n",
       "      <td>[Da, fuck, go, people, man, room, woman, room,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>77665</td>\n",
       "      <td>@USER Tbh these days i just don't like people ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>(@USER, Tbh, these, days, i, just, do, n't, li...</td>\n",
       "      <td>[tbh, day, like, people, general, connect, peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>25440</td>\n",
       "      <td>@USER @USER @USER She?  To whom are you referr...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(@USER, @USER, @USER, She, ?,  , To, whom, are...</td>\n",
       "      <td>[refer, Hillary, know, tiresome, Bernie, suppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12609</td>\n",
       "      <td>The only thing the Democrats have is lying and...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>(The, only, thing, the, Democrats, have, is, l...</td>\n",
       "      <td>[thing, Democrats, lie, stall, stop, Trump, Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12108</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>(@USER, @USER, @USER, @USER, @USER, @USER, @US...</td>\n",
       "      <td>[smart, think, Gen, Flynn, sentencing, keep, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14726</td>\n",
       "      <td>@USER @USER @USER That's expected if you placa...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>(@USER, @USER, @USER, That, 's, expected, if, ...</td>\n",
       "      <td>[expect, placate, violent, leftist, terrorist,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>84102</td>\n",
       "      <td>4 out of 10 British people are basically full-...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>(4, out, of, 10, British, people, are, basical...</td>\n",
       "      <td>[4, 10, british, people, basically, racist, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>98992</td>\n",
       "      <td>@USER Fuck off</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>(@USER, Fuck, off)</td>\n",
       "      <td>[fuck]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>33853</td>\n",
       "      <td>@USER @USER The prison system is so fucked.  W...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "      <td>(@USER, @USER, The, prison, system, is, so, fu...</td>\n",
       "      <td>[prison, system, fucked, get, away, potentiall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              tweet subtask_a  \\\n",
       "7   52415  @USER was literally just talking about this lo...       OFF   \n",
       "9   13384  @USER Canada doesn’t need another CUCK! We alr...       OFF   \n",
       "12  28414  @USER you are a lying corrupt traitor!!! Nobod...       OFF   \n",
       "19  28195  @USER @USER @USER gun control! That is all the...       OFF   \n",
       "20  56117  @USER @USER @USER @USER LOL!!!   Throwing the ...       OFF   \n",
       "22  12681  @USER @USER Kind of like when conservatives wa...       OFF   \n",
       "23  82904  @USER @USER Da fuck is going on people?   Ther...       OFF   \n",
       "25  77665  @USER Tbh these days i just don't like people ...       OFF   \n",
       "29  25440  @USER @USER @USER She?  To whom are you referr...       OFF   \n",
       "32  12609  The only thing the Democrats have is lying and...       OFF   \n",
       "36  12108  @USER @USER @USER @USER @USER @USER @USER @USE...       OFF   \n",
       "37  14726  @USER @USER @USER That's expected if you placa...       OFF   \n",
       "54  84102  4 out of 10 British people are basically full-...       OFF   \n",
       "57  98992                                     @USER Fuck off       OFF   \n",
       "59  33853  @USER @USER The prison system is so fucked.  W...       OFF   \n",
       "\n",
       "   subtask_b subtask_c                                             tokens  \\\n",
       "7        TIN       GRP  (@USER, was, literally, just, talking, about, ...   \n",
       "9        TIN       IND  (@USER, Canada, does, n’t, need, another, CUCK...   \n",
       "12       TIN       IND  (@USER, you, are, a, lying, corrupt, traitor, ...   \n",
       "19       TIN       OTH  (@USER, @USER, @USER, gun, control, !, That, i...   \n",
       "20       TIN       IND  (@USER, @USER, @USER, @USER, LOL, !, !, !,   ,...   \n",
       "22       TIN       GRP  (@USER, @USER, Kind, of, like, when, conservat...   \n",
       "23       TIN       GRP  (@USER, @USER, Da, fuck, is, going, on, people...   \n",
       "25       TIN       IND  (@USER, Tbh, these, days, i, just, do, n't, li...   \n",
       "29       UNT       NaN  (@USER, @USER, @USER, She, ?,  , To, whom, are...   \n",
       "32       TIN       GRP  (The, only, thing, the, Democrats, have, is, l...   \n",
       "36       TIN       IND  (@USER, @USER, @USER, @USER, @USER, @USER, @US...   \n",
       "37       TIN       GRP  (@USER, @USER, @USER, That, 's, expected, if, ...   \n",
       "54       TIN       GRP  (4, out, of, 10, British, people, are, basical...   \n",
       "57       TIN       IND                                 (@USER, Fuck, off)   \n",
       "59       TIN       OTH  (@USER, @USER, The, prison, system, is, so, fu...   \n",
       "\n",
       "                                               lemmas  \n",
       "7   [literally, talk, lol, mass, shooting, like, s...  \n",
       "9   [Canada, need, CUCK, LooneyLeft, Liberals, f**...  \n",
       "12  [lie, corrupt, traitor, want, hear, anymore, l...  \n",
       "19                           [gun, control, kid, ask]  \n",
       "20  [LOL, throw, BULLSHIT, Flag, nonsense, putupor...  \n",
       "22  [kind, like, conservative, wanna, associate, l...  \n",
       "23  [Da, fuck, go, people, man, room, woman, room,...  \n",
       "25  [tbh, day, like, people, general, connect, peo...  \n",
       "29  [refer, Hillary, know, tiresome, Bernie, suppo...  \n",
       "32  [thing, Democrats, lie, stall, stop, Trump, Pr...  \n",
       "36  [smart, think, Gen, Flynn, sentencing, keep, r...  \n",
       "37  [expect, placate, violent, leftist, terrorist,...  \n",
       "54  [4, 10, british, people, basically, racist, 4,...  \n",
       "57                                             [fuck]  \n",
       "59  [prison, system, fucked, get, away, potentiall...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[5:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets['length_lemmas'] = tweets['lemmas'].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3\n",
       "1     8\n",
       "3     5\n",
       "5     2\n",
       "6     4\n",
       "7    16\n",
       "9    10\n",
       "Name: length_lemmas, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[:10, 'length_lemmas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_length_tweet = max(tweets['length_lemmas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ładowanie danych testowych(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_level_b = pd.read_csv('data/testset-levelb.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels_level_b = pd.read_csv('data/labels-levelb.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels_level_b = labels_level_b.rename(columns={0:'id', 1:'subtask_b'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_b = pd.merge(test_level_b, labels_level_b, on = \"id\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15923</td>\n",
       "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60133</td>\n",
       "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83681</td>\n",
       "      <td>. . . What the fuck did he do this time?</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65507</td>\n",
       "      <td>@USER Do you get the feeling he is kissing @US...</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12588</td>\n",
       "      <td>@USER Nigga ware da hits at</td>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_b\n",
       "0  15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       TIN\n",
       "1  60133  #NoPasaran: Unity demo to oppose the far-right...       TIN\n",
       "2  83681           . . . What the fuck did he do this time?       TIN\n",
       "3  65507  @USER Do you get the feeling he is kissing @US...       TIN\n",
       "4  12588                        @USER Nigga ware da hits at       UNT"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_b = test_b.dropna(subset=['subtask_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opracowanie danych testowych (część a)\n",
    "Takie same modyfikacje jak dla danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_b['tokens'] = test_b['tweet'].apply(nlp)\n",
    "test_b['lemmas'] = test_b['tokens'].apply \\\n",
    "    (lambda list_tokens : [token.lemma_.strip() for token in list_tokens if ('@' not in token.lemma_\n",
    "                                                                             and '#' not in token.lemma_ and 'url' not in token.lemma_\n",
    "                                                                             and not token.is_stop and not token.is_punct and token.lemma_ != ' '\n",
    "                                                                             and token.lemma_ != '  ' and token.lemma_ != '   '\n",
    "                                                                             and token.lemma_ != '    ' and token.lemma_.strip() != '')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_b['length_lemmas'] = test_b['lemmas'].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_b['length_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>length_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15923</td>\n",
       "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>(#, WhoIsQ, #, WheresTheServer, #, DumpNike, #...</td>\n",
       "      <td>[WhoIsQ, wherestheserver, DumpNike, DECLASFISA...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60133</td>\n",
       "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>(#, NoPasaran, :, Unity, demo, to, oppose, the...</td>\n",
       "      <td>[NoPasaran, unity, demo, oppose, far, right, L...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83681</td>\n",
       "      <td>. . . What the fuck did he do this time?</td>\n",
       "      <td>TIN</td>\n",
       "      <td>(., ., ., What, the, fuck, did, he, do, this, ...</td>\n",
       "      <td>[fuck, time]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65507</td>\n",
       "      <td>@USER Do you get the feeling he is kissing @US...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>(@USER, Do, you, get, the, feeling, he, is, ki...</td>\n",
       "      <td>[feeling, kiss, humiliate, later]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12588</td>\n",
       "      <td>@USER Nigga ware da hits at</td>\n",
       "      <td>UNT</td>\n",
       "      <td>(@USER, Nigga, ware, da, hits, at)</td>\n",
       "      <td>[Nigga, ware, da, hit]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_b  \\\n",
       "0  15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       TIN   \n",
       "1  60133  #NoPasaran: Unity demo to oppose the far-right...       TIN   \n",
       "2  83681           . . . What the fuck did he do this time?       TIN   \n",
       "3  65507  @USER Do you get the feeling he is kissing @US...       TIN   \n",
       "4  12588                        @USER Nigga ware da hits at       UNT   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  (#, WhoIsQ, #, WheresTheServer, #, DumpNike, #...   \n",
       "1  (#, NoPasaran, :, Unity, demo, to, oppose, the...   \n",
       "2  (., ., ., What, the, fuck, did, he, do, this, ...   \n",
       "3  (@USER, Do, you, get, the, feeling, he, is, ki...   \n",
       "4                 (@USER, Nigga, ware, da, hits, at)   \n",
       "\n",
       "                                              lemmas  length_lemmas  \n",
       "0  [WhoIsQ, wherestheserver, DumpNike, DECLASFISA...             24  \n",
       "1  [NoPasaran, unity, demo, oppose, far, right, L...              9  \n",
       "2                                       [fuck, time]              2  \n",
       "3                  [feeling, kiss, humiliate, later]              4  \n",
       "4                             [Nigga, ware, da, hit]              4  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_length_tweet_test = max(test_b['length_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_tweet_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Maksymalna długość wektora z lematami z tweetów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_width = max(max_length_tweet, max_length_tweet_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Funkcje do przekszałcania danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_words_to_numbers(lemmas_series, dict_ = dict()):\n",
    "    # dict_ = dict()\n",
    "    for row in lemmas_series:\n",
    "        for lemma in row:\n",
    "            if lemma not in dict_:\n",
    "                dict_[lemma] = len(dict_) + 1\n",
    "\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lemmas_to_numbers(row, max_list_lemmas, dict_):\n",
    "    list_numbers = []\n",
    "    for i in range(max_list_lemmas - len(row)):\n",
    "        list_numbers.append(0)\n",
    "\n",
    "    for lemma in row:\n",
    "        list_numbers.append(dict_[lemma])\n",
    "\n",
    "    array_numbers = np.array(list_numbers, dtype=np.int32)\n",
    "    return array_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Powrót do opracowywania danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_lemmas = convert_words_to_numbers(tweets['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$',\n",
       " \"'em\",\n",
       " '+',\n",
       " '-Antifa',\n",
       " '-Awkward',\n",
       " '-Bill',\n",
       " '-GOP',\n",
       " '-Human',\n",
       " '-I',\n",
       " '-Illegal']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict_lemmas)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# zamiana lematu na liczbe ze slownika ktory odpowiada danemu slowu\n",
    "tweets['numbers'] = tweets['lemmas'].apply(lambda row : lemmas_to_numbers(row, max_width, dict_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "5    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "6    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: numbers, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['numbers'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# przypisywanie X_train kolumny numbers skonwertowanej na tablice numpy\n",
    "X_train = tweets['numbers'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# łączenie wierszy tablic w jedną tablicę 2D\n",
    "X_train = np.stack(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# konwertowanie tablicy 2d do tensora\n",
    "X_train = torch.FloatTensor(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ustawianie kolumn z etykietami na poszczególne zadania jako type które przechowują kategorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = ['subtask_a', 'subtask_b', 'subtask_c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    tweets[col] = tweets[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets['labels_b'] = tweets['subtask_b'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "3    1\n",
       "5    0\n",
       "Name: labels_b, dtype: int8"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OFFENSIVE jest jako 1, a NOT OFFENSIVE jest jako 0\n",
    "tweets.loc[:5, 'labels_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>length_lemmas</th>\n",
       "      <th>numbers</th>\n",
       "      <th>labels_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(@USER, She, should, ask, a, few, native, Amer...</td>\n",
       "      <td>[ask, native, Americans]</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>(@USER, @USER, Go, home, you, ’re, drunk, !, !...</td>\n",
       "      <td>[home, drunk, MAGA, Trump2020, 👊, 🇺, 🇸, 👊]</td>\n",
       "      <td>8</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(@USER, Someone, should'veTaken, \", this, piec...</td>\n",
       "      <td>[should'vetaken, piece, shit, volcano, 😂]</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97670</td>\n",
       "      <td>@USER Liberals are all Kookoo !!!</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "      <td>(@USER, Liberals, are, all, Kookoo, !, !, !)</td>\n",
       "      <td>[liberal, Kookoo]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>77444</td>\n",
       "      <td>@USER @USER Oh noes! Tough shit.</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(@USER, @USER, Oh, noes, !, Tough, shit, .)</td>\n",
       "      <td>[oh, no, tough, shit]</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13223</th>\n",
       "      <td>63482</td>\n",
       "      <td>@USER is advocating for conduct within bounds ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>(@USER, is, advocating, for, conduct, within, ...</td>\n",
       "      <td>[advocate, conduct, bound, Human, Rights, terr...</td>\n",
       "      <td>23</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>87416</td>\n",
       "      <td>@USER @USER @USER @USER Liars like the Antifa ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>(@USER, @USER, @USER, @USER, Liars, like, the,...</td>\n",
       "      <td>[liar, like, Antifa, twin, vigorously, defend]</td>\n",
       "      <td>6</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>95338</td>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>(@USER, Sometimes, I, get, strong, vibes, from...</td>\n",
       "      <td>[strong, vibe, people, man, vibe, ten, million...</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>82921</td>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "      <td>(@USER, And, why, report, this, garbage, .,  ,...</td>\n",
       "      <td>[report, garbage, crap]</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>27429</td>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(@USER, Pussy)</td>\n",
       "      <td>[Pussy]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4400 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "5      97670                  @USER Liberals are all Kookoo !!!       OFF   \n",
       "6      77444                   @USER @USER Oh noes! Tough shit.       OFF   \n",
       "...      ...                                                ...       ...   \n",
       "13223  63482  @USER is advocating for conduct within bounds ...       OFF   \n",
       "13227  87416  @USER @USER @USER @USER Liars like the Antifa ...       OFF   \n",
       "13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n",
       "13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n",
       "13238  27429                                        @USER Pussy       OFF   \n",
       "\n",
       "      subtask_b subtask_c                                             tokens  \\\n",
       "0           UNT       NaN  (@USER, She, should, ask, a, few, native, Amer...   \n",
       "1           TIN       IND  (@USER, @USER, Go, home, you, ’re, drunk, !, !...   \n",
       "3           UNT       NaN  (@USER, Someone, should'veTaken, \", this, piec...   \n",
       "5           TIN       OTH       (@USER, Liberals, are, all, Kookoo, !, !, !)   \n",
       "6           UNT       NaN        (@USER, @USER, Oh, noes, !, Tough, shit, .)   \n",
       "...         ...       ...                                                ...   \n",
       "13223       TIN       GRP  (@USER, is, advocating, for, conduct, within, ...   \n",
       "13227       TIN       GRP  (@USER, @USER, @USER, @USER, Liars, like, the,...   \n",
       "13235       TIN       IND  (@USER, Sometimes, I, get, strong, vibes, from...   \n",
       "13237       TIN       OTH  (@USER, And, why, report, this, garbage, .,  ,...   \n",
       "13238       UNT       NaN                                     (@USER, Pussy)   \n",
       "\n",
       "                                                  lemmas  length_lemmas  \\\n",
       "0                               [ask, native, Americans]              3   \n",
       "1             [home, drunk, MAGA, Trump2020, 👊, 🇺, 🇸, 👊]              8   \n",
       "3              [should'vetaken, piece, shit, volcano, 😂]              5   \n",
       "5                                      [liberal, Kookoo]              2   \n",
       "6                                  [oh, no, tough, shit]              4   \n",
       "...                                                  ...            ...   \n",
       "13223  [advocate, conduct, bound, Human, Rights, terr...             23   \n",
       "13227     [liar, like, Antifa, twin, vigorously, defend]              6   \n",
       "13235  [strong, vibe, people, man, vibe, ten, million...             10   \n",
       "13237                            [report, garbage, crap]              3   \n",
       "13238                                            [Pussy]              1   \n",
       "\n",
       "                                                 numbers  labels_b  \n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n",
       "5      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n",
       "6      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n",
       "...                                                  ...       ...  \n",
       "13223  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n",
       "13227  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n",
       "13235  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n",
       "13237  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n",
       "13238  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n",
       "\n",
       "[4400 rows x 10 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                           86426\n",
       "tweet            @USER She should ask a few native Americans wh...\n",
       "subtask_a                                                      OFF\n",
       "subtask_b                                                      UNT\n",
       "subtask_c                                                      NaN\n",
       "tokens           (@USER, She, should, ask, a, few, native, Amer...\n",
       "lemmas                                    [ask, native, Americans]\n",
       "length_lemmas                                                    3\n",
       "numbers          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "labels_b                                                         1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train = tweets['labels_b'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]], dtype=torch.int8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = torch.cat((X_train, y_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Opracowywanie danych testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_lemmas = convert_words_to_numbers(test_b['lemmas'], dict_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$',\n",
       " \"'cause\",\n",
       " \"'em\",\n",
       " '+',\n",
       " '-Antifa',\n",
       " '-Awkward',\n",
       " '-Bill',\n",
       " '-GOP',\n",
       " '-Human',\n",
       " '-I']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict_lemmas)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# zamiana lematu na liczbe ze slownika ktory odpowiada danemu slowu\n",
    "test_b['numbers'] = test_b['lemmas'].apply(lambda row : lemmas_to_numbers(row, max_width, dict_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [WhoIsQ, wherestheserver, DumpNike, DECLASFISA...\n",
       "1    [NoPasaran, unity, demo, oppose, far, right, L...\n",
       "2                                         [fuck, time]\n",
       "3                    [feeling, kiss, humiliate, later]\n",
       "4                               [Nigga, ware, da, hit]\n",
       "Name: lemmas, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_b['lemmas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "5    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: numbers, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_b.loc[:5, 'numbers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Robienie tego samego procesu co wcześniej dla danych testowych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test = test_b['numbers'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cat_cols = ['subtask_a', 'subtask_b', 'subtask_c']\n",
    "# for col in cat_cols:\n",
    "#     X_test[col] = X_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_b['subtask_b'] = test_b['subtask_b'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_b['labels_b'] = test_b['subtask_b'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "96     0\n",
       "97     0\n",
       "98     0\n",
       "99     0\n",
       "100    0\n",
       "Name: labels_b, Length: 101, dtype: int8"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OFFENSIVE jest jako 1, a NOT OFFENSIVE jest jako 0\n",
    "test_b.loc[:100, 'labels_b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test = test_b['labels_b'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test = torch.tensor(y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1]], dtype=torch.int8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_test_b = torch.cat((X_test, y_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_test_b = data_test_b.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generowanie embedingów na podstawie embedingów ze spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings.append(np.zeros(96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key, value in dict_lemmas.items():\n",
    "    embeddings.append(nlp(key)[0].vector)\n",
    "    # print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10528"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_lemmas_inverted = {v: k for k, v in dict_lemmas.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dict_lemmas_inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "# sprawdzanie embeddingów - czy się dobrze zapisały\n",
    "for key, value in dict_lemmas.items():\n",
    "    comparison = embeddings[value] == nlp(key)[0].vector\n",
    "    if comparison.all() == False:\n",
    "        print('false')\n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.676073  ,  0.09062457, -0.19625556,  0.9512366 ,  0.7504209 ,\n",
       "        1.1548312 ,  1.0129769 , -0.8388504 , -1.1186899 ,  0.71350086,\n",
       "       -0.4241021 , -0.30965236,  0.12993638, -0.2392391 , -1.0840138 ,\n",
       "        0.61949897,  0.04032705, -0.10979578, -1.0923057 , -0.11414534,\n",
       "       -0.20071098,  0.01481187, -0.4070547 , -0.3393178 , -0.19887975,\n",
       "       -0.00512362, -0.44030216, -0.26272678, -0.51703787,  0.02113847,\n",
       "       -0.84284085, -0.33209977,  0.92871165, -0.4222517 ,  0.4632333 ,\n",
       "       -0.5070641 ,  1.0883812 ,  0.53153765, -0.6991434 , -0.24793866,\n",
       "        0.2177751 ,  0.76133025, -0.2888482 ,  1.6803848 ,  1.1069292 ,\n",
       "       -0.44316196,  0.4076068 , -0.2660989 , -0.54845977, -0.55120814,\n",
       "        0.23734902,  0.02351934,  0.45318043,  0.856611  ,  0.29240057,\n",
       "       -1.0060917 ,  1.32265   , -1.1334491 ,  0.20376281, -0.6440315 ,\n",
       "        0.41097862,  0.3831125 ,  1.1056539 , -0.34738913,  0.60588783,\n",
       "       -0.09251603, -0.41251144, -0.6224398 ,  0.683713  ,  0.34403592,\n",
       "       -0.16671339, -0.6788694 , -0.04922862, -0.5299547 , -0.25115994,\n",
       "        0.7615716 ,  0.00928873,  0.22849807, -0.3107491 , -0.42255074,\n",
       "        0.11905795, -0.03290644,  0.1583575 ,  1.0251714 , -0.8566352 ,\n",
       "        0.17710371,  0.2147669 , -1.0185226 ,  0.522235  ,  0.09653302,\n",
       "       -0.3551365 ,  0.5546729 , -0.36672962, -0.2642688 , -0.8536765 ,\n",
       "       -0.2873654 ], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emb_torch = torch.tensor(embeddings, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10529, 96])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_torch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, emb_vectors, in_features=18, h1=80, h2=50, h3=None, embedding_dim=None, out_features=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # warstwa embeddingów\n",
    "        self.embedding = nn.Embedding.from_pretrained(emb_vectors)\n",
    "\n",
    "        # self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # dropout layer - losowe pomijanie uczenia się pewnych neuronów\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc1 = nn.Linear(embedding_dim * in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        if h3 is None:\n",
    "            self.out = nn.Linear(h2, out_features)\n",
    "        # self.sig = nn.Sigmoid()\n",
    "        else:\n",
    "            self.fc3 = nn.Linear(h2, h3)\n",
    "            self.out = nn.Linear(h3, out_features)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = x.long()\n",
    "        # print(x.shape)\n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "        # print(embeds.shape)\n",
    "        embeds = embeds.view(embeds.shape[0], -1)\n",
    "        # print(embeds.shape)\n",
    "        x = torch.sigmoid(self.fc1(embeds))\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        if h3 is not None:\n",
    "            x = torch.sigmoid(self.fc3(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ustawnia modelu i sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max width: 73\n"
     ]
    }
   ],
   "source": [
    "print('max width: 73')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 50\n",
    "vocab_size = len(dict_lemmas) + 1\n",
    "embedding_dim = emb_torch.shape[1]\n",
    "h1 = 1000\n",
    "h2 = 1000\n",
    "h3 = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "test_dataset_loader_b = torch.utils.data.DataLoader(data_test_b, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tworzenie instancji modelu\n",
    "Ustawianie funkcji straty i optymalizatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tworzenie numpy array z listy liczb (odpowiadających lematom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(32)\n",
    "model = Model(emb_torch, max_width, h1, h2, h3, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding): Embedding(10529, 96)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=3840, out_features=1000, bias=True)\n",
       "  (fc2): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  (out): Linear(in_features=1000, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ustawianie nauki sieci i samo uczenie się"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "losses_test = []\n",
    "accuracy = []\n",
    "accuracy_test = []\n",
    "train_count = len(tweets)\n",
    "test_count_a = len(test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on the first batch: 0.031090009957551956\n",
      "Loss on the first batch on test data: 2.660745143890381\n",
      "torch.Size([])\n",
      " epoch: 0 | loss: 0.00015643726695667613 | predicted: 4378 |accuracy: 99.5 | test loss: 0.03876928898195426 | predicted: 203 | test accuracy: 84.58333587646484\n",
      " epoch: 1 | loss: 0.0002928039160641757 | predicted: 4371 |accuracy: 99.34091186523438 | test loss: 0.04538178294897079 | predicted: 203 | test accuracy: 84.58333587646484\n",
      " epoch: 2 | loss: 0.0003834684057669206 | predicted: 4363 |accuracy: 99.15908813476562 | test loss: 0.04487745414177577 | predicted: 207 | test accuracy: 86.25\n",
      " epoch: 3 | loss: 0.00034466028213500974 | predicted: 4369 |accuracy: 99.29545593261719 | test loss: 0.04226009224851926 | predicted: 207 | test accuracy: 86.25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25035/61863183.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25035/245378880.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# print(embeds.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for e in range(epochs):\n",
    "    loss_epoch = torch.empty(0)\n",
    "    correct_epoch = 0\n",
    "\n",
    "    loss_epoch_test = np.empty(0)\n",
    "    correct_epoch_test = 0\n",
    "\n",
    "    for batch_num, batch in enumerate(train_dataset_loader):\n",
    "        X_train = batch[:,:-1]\n",
    "        y_train = batch[:,-1].reshape(-1,1)\n",
    "        y_pred = model.forward(X_train)\n",
    "\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        if (e == 0 and batch_num == 0):\n",
    "            print(f'Loss on the first batch: {loss}')\n",
    "\n",
    "        # print(loss.item())\n",
    "        loss_epoch = np.append(loss_epoch, loss.detach().cpu().numpy())\n",
    "        # losses.append(loss.item())\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        predicted = torch.round(y_pred)\n",
    "        # print(y_train)\n",
    "        predicted = (predicted == y_train).sum().cpu()\n",
    "        pred_cpu = predicted.cpu()\n",
    "        # print(f'pred_cpu: {pred_cpu}')\n",
    "        correct_epoch += predicted\n",
    "\n",
    "# przechodzenie przez dane testowe\n",
    "    with torch.no_grad():\n",
    "        for batch_num_test, batch_test in enumerate(test_dataset_loader_b):\n",
    "            X_test = batch_test[:,:-1]\n",
    "            y_test = batch_test[:,-1].reshape(-1,1)\n",
    "            y_pred_test = model.forward(X_test)\n",
    "\n",
    "            loss_test = criterion(y_pred_test, y_test)\n",
    "            if (e == 0 and batch_num_test == 0):\n",
    "                print(f'Loss on the first batch on test data: {loss_test}')\n",
    "                print(loss_test.shape)\n",
    "\n",
    "            # print(loss.item())\n",
    "            loss_epoch_test = np.append(loss_epoch_test, loss_test.item())\n",
    "            # print(loss_test)\n",
    "            # losses.append(loss.item())\n",
    "\n",
    "            predicted = torch.round(y_pred_test)\n",
    "            # print(predicted)\n",
    "            # print(y_test)\n",
    "            predicted = (predicted == y_test).sum()\n",
    "            pred_cpu = predicted.cpu()\n",
    "            # print(f'pred_cpu: {pred_cpu}')\n",
    "            correct_epoch_test += predicted\n",
    "\n",
    "        loss_epoch_test = loss_epoch_test.sum() / test_count_a\n",
    "        losses_test.append(loss_epoch_test)\n",
    "        accuracy_epoch_test = correct_epoch_test * 100/test_count_a\n",
    "        accuracy_epoch_test_cpu = accuracy_epoch_test.cpu()\n",
    "        accuracy_test.append(accuracy_epoch_test_cpu)\n",
    "\n",
    "    loss_epoch = loss_epoch.sum() / train_count\n",
    "    losses.append(loss_epoch)\n",
    "    accuracy_epoch = correct_epoch * 100/train_count\n",
    "    accuracy_epoch_cpu = accuracy_epoch.cpu()\n",
    "    accuracy.append(accuracy_epoch)\n",
    "\n",
    "\n",
    "    # print(f'Test accuracy: {correct_epoch.item()}/{train_count} = {correct.item() * 100 / (test_count):7.3f}%')\n",
    "    print(f' epoch: {e} | loss: {loss_epoch} | predicted: {correct_epoch} |' \\\n",
    "            + f'accuracy: {accuracy_epoch} | test loss: {loss_epoch_test} | ' \\\n",
    "            + f'predicted: {correct_epoch_test} | test accuracy: {accuracy_epoch_test}')\n",
    "\n",
    "duration = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Rysowanie funkcji straty i accuracy na przestrzeni epok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (105,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25035/308884905.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Losses and epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (105,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6oAAAGfCAYAAABWVC8pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVy0lEQVR4nO3dUYjl53nf8d/T3QgaJ41MtAnuSiZqka3shVXsiWxK0yoNrbXqxRLwheQQUREQolHIpUQgyYVvkotCMJazLEYI30QXjUg2RYkolMQFV6lGYMteG5mtTKWtDFrFwQUbKtZ+cjGjeDwa7Zzdc2b22bOfDwzs/5x3Z15eZnj4nnPmTHV3AAAAYIp/dK03AAAAADsJVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGCUfUO1qp6sqjeq6qvvcn9V1aer6nxVvVRVH179NgGAt5nNAKy7RZ5RfSrJvZe5/2SSO7Y/Hk7yR8tvCwC4jKdiNgOwxvYN1e7+QpJvX2bJqSSf7y3PJ7m5qt63qg0CAD/KbAZg3R1dwec4nuS1HdcXtm/71u6FVfVwth7ZzXve856P3HnnnSv48gCQvPjii29297FrvY8hzGYArrllZvMqQrX2uK33WtjdZ5KcSZKNjY3e3NxcwZcHgKSq/s+13sMgZjMA19wys3kV7/p7IcltO65vTfL6Cj4vAHB1zGYArmurCNWzSR7cfofBjyX5Tne/46VFAMChMZsBuK7t+9LfqvrjJPckuaWqLiT5vSQ/liTdfTrJs0nuS3I+yfeSPHRQmwUAzGYA1t++odrdD+xzfyf5jZXtCAC4LLMZgHW3ipf+AgAAwMoIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjLJQqFbVvVX1clWdr6rH97j/p6rqz6vqy1V1rqoeWv1WAYC3mc0ArLN9Q7WqjiR5IsnJJCeSPFBVJ3Yt+40kX+vuu5Lck+Q/V9VNK94rABCzGYD1t8gzqncnOd/dr3T3W0meTnJq15pO8pNVVUl+Ism3k1xa6U4BgLeZzQCstUVC9XiS13ZcX9i+bafPJPn5JK8n+UqS3+ruH+z+RFX1cFVtVtXmxYsXr3LLAHDDM5sBWGuLhGrtcVvvuv54ki8l+adJ/kWSz1TVP3nHf+o+090b3b1x7NixK9wqALDNbAZgrS0SqheS3Lbj+tZsPTq700NJnukt55N8M8mdq9kiALCL2QzAWlskVF9IckdV3b79Jgz3Jzm7a82rSX45SarqZ5N8MMkrq9woAPAPzGYA1trR/RZ096WqejTJc0mOJHmyu89V1SPb959O8qkkT1XVV7L1cqTHuvvNA9w3ANywzGYA1t2+oZok3f1skmd33XZ6x79fT/LvV7s1AODdmM0ArLNFXvoLAAAAh0aoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABglIVCtaruraqXq+p8VT3+LmvuqaovVdW5qvrr1W4TANjJbAZgnR3db0FVHUnyRJJ/l+RCkheq6mx3f23HmpuTfDbJvd39alX9zAHtFwBueGYzAOtukWdU705yvrtf6e63kjyd5NSuNZ9M8kx3v5ok3f3GarcJAOxgNgOw1hYJ1eNJXttxfWH7tp0+kOS9VfVXVfViVT241yeqqoerarOqNi9evHh1OwYAzGYA1toioVp73Na7ro8m+UiS/5Dk40l+p6o+8I7/1H2muze6e+PYsWNXvFkAIInZDMCa2/d3VLP1KO1tO65vTfL6Hmve7O7vJvluVX0hyV1JvrGSXQIAO5nNAKy1RZ5RfSHJHVV1e1XdlOT+JGd3rfmzJL9YVUer6seTfDTJ11e7VQBgm9kMwFrb9xnV7r5UVY8meS7JkSRPdve5qnpk+/7T3f31qvrLJC8l+UGSz3X3Vw9y4wBwozKbAVh31b37V1oOx8bGRm9ubl6Trw3A+qmqF7t741rv43pmNgOwSsvM5kVe+gsAAACHRqgCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoC4VqVd1bVS9X1fmqevwy636hqr5fVZ9Y3RYBgN3MZgDW2b6hWlVHkjyR5GSSE0keqKoT77LuD5I8t+pNAgA/ZDYDsO4WeUb17iTnu/uV7n4rydNJTu2x7jeT/EmSN1a4PwDgncxmANbaIqF6PMlrO64vbN/2D6rqeJJfSXL6cp+oqh6uqs2q2rx48eKV7hUA2GI2A7DWFgnV2uO23nX9h0ke6+7vX+4TdfeZ7t7o7o1jx44tuEUAYBezGYC1dnSBNReS3Lbj+tYkr+9as5Hk6apKkluS3FdVl7r7T1exSQDgR5jNAKy1RUL1hSR3VNXtSf5vkvuTfHLngu6+/e1/V9VTSf6rQQgAB8ZsBmCt7Ruq3X2pqh7N1jsGHknyZHefq6pHtu+/7O++AACrZTYDsO4WeUY13f1skmd33bbnEOzu/7j8tgCAyzGbAVhni7yZEgAAABwaoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFEWCtWqureqXq6q81X1+B73/2pVvbT98cWqumv1WwUA3mY2A7DO9g3VqjqS5IkkJ5OcSPJAVZ3YteybSf5Nd38oyaeSnFn1RgGALWYzAOtukWdU705yvrtf6e63kjyd5NTOBd39xe7+u+3L55PcutptAgA7mM0ArLVFQvV4ktd2XF/Yvu3d/HqSv9jrjqp6uKo2q2rz4sWLi+8SANjJbAZgrS0SqrXHbb3nwqpfytYwfGyv+7v7THdvdPfGsWPHFt8lALCT2QzAWju6wJoLSW7bcX1rktd3L6qqDyX5XJKT3f23q9keALAHsxmAtbbIM6ovJLmjqm6vqpuS3J/k7M4FVfX+JM8k+bXu/sbqtwkA7GA2A7DW9n1GtbsvVdWjSZ5LciTJk919rqoe2b7/dJLfTfLTST5bVUlyqbs3Dm7bAHDjMpsBWHfVveevtBy4jY2N3tzcvCZfG4D1U1UvCrHlmM0ArNIys3mRl/4CAADAoRGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwilAFAABgFKEKAADAKEIVAACAUYQqAAAAowhVAAAARhGqAAAAjCJUAQAAGEWoAgAAMIpQBQAAYBShCgAAwChCFQAAgFGEKgAAAKMIVQAAAEYRqgAAAIwiVAEAABhFqAIAADCKUAUAAGAUoQoAAMAoQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYZaFQrap7q+rlqjpfVY/vcX9V1ae373+pqj68+q0CAG8zmwFYZ/uGalUdSfJEkpNJTiR5oKpO7Fp2Mskd2x8PJ/mjFe8TANhmNgOw7hZ5RvXuJOe7+5XufivJ00lO7VpzKsnne8vzSW6uqveteK8AwBazGYC1dnSBNceTvLbj+kKSjy6w5niSb+1cVFUPZ+tR3ST5/1X11SvaLbvdkuTNa72JNeAcl+cMl+cMl/fBa72BQ2Q2z+VneTWc4/Kc4fKc4fKuejYvEqq1x219FWvS3WeSnEmSqtrs7o0Fvj7vwhmuhnNcnjNcnjNcXlVtXus9HCKzeShnuBrOcXnOcHnOcHnLzOZFXvp7IcltO65vTfL6VawBAFbDbAZgrS0Sqi8kuaOqbq+qm5Lcn+TsrjVnkzy4/Q6DH0vyne7+1u5PBACshNkMwFrb96W/3X2pqh5N8lySI0me7O5zVfXI9v2nkzyb5L4k55N8L8lDC3ztM1e9a97mDFfDOS7PGS7PGS7vhjlDs3k0Z7gaznF5znB5znB5V32G1f2OX1cBAACAa2aRl/4CAADAoRGqAAAAjHLgoVpV91bVy1V1vqoe3+P+qqpPb9//UlV9+KD3dL1Z4Ax/dfvsXqqqL1bVXddin5Ptd4Y71v1CVX2/qj5xmPu7HixyhlV1T1V9qarOVdVfH/Yep1vgZ/mnqurPq+rL22e4yO8U3lCq6smqeuPd/tanmbIYs3l5ZvPyzOblmc3LM5uXd2CzubsP7CNbb/Dwv5P8syQ3JflykhO71tyX5C+y9ffePpbkbw5yT9fbx4Jn+C+TvHf73yed4ZWf4Y51/z1bb0DyiWu970kfC34f3pzka0nev339M9d635M+FjzD307yB9v/Ppbk20luutZ7n/SR5F8n+XCSr77L/WbK/mdoNh/OGZrNS57hjnVm81Weodm8kjM0m/c/xwOZzQf9jOrdSc539yvd/VaSp5Oc2rXmVJLP95bnk9xcVe874H1dT/Y9w+7+Ynf/3fbl89n6W3n80CLfh0nym0n+JMkbh7m568QiZ/jJJM9096tJ0t3O8Uctcoad5CerqpL8RLaG4aXD3eZs3f2FbJ3LuzFT9mc2L89sXp7ZvDyzeXlm8woc1Gw+6FA9nuS1HdcXtm+70jU3sis9n1/P1iMW/NC+Z1hVx5P8SpLTh7iv68ki34cfSPLeqvqrqnqxqh48tN1dHxY5w88k+fkkryf5SpLf6u4fHM721oaZsj+zeXlm8/LM5uWZzcszmw/HVc2Uff+O6pJqj9t2/z2cRdbcyBY+n6r6pWwNw391oDu6/ixyhn+Y5LHu/v7WA2bsssgZHk3ykSS/nOQfJ/mfVfV8d3/joDd3nVjkDD+e5EtJ/m2Sf57kv1XV/+ju/3fAe1snZsr+zOblmc3LM5uXZzYvz2w+HFc1Uw46VC8kuW3H9a3ZejTiStfcyBY6n6r6UJLPJTnZ3X97SHu7XixyhhtJnt4ehLckua+qLnX3nx7KDudb9Gf5ze7+bpLvVtUXktyVxDDcssgZPpTk93vrFzrOV9U3k9yZ5H8dzhbXgpmyP7N5eWbz8szm5ZnNyzObD8dVzZSDfunvC0nuqKrbq+qmJPcnObtrzdkkD26/G9THknynu791wPu6nux7hlX1/iTPJPk1j5Dtad8z7O7bu/vnuvvnkvyXJP/JIPwRi/ws/1mSX6yqo1X140k+muTrh7zPyRY5w1ez9ah3qupnk3wwySuHusvrn5myP7N5eWbz8szm5ZnNyzObD8dVzZQDfUa1uy9V1aNJnsvWu2o92d3nquqR7ftPZ+td3O5Lcj7J97L1qAXbFjzD303y00k+u/2o46Xu3rhWe55mwTPkMhY5w+7+elX9ZZKXkvwgyee6e8+3Kb8RLfh9+KkkT1XVV7L1MpnHuvvNa7bpgarqj5Pck+SWqrqQ5PeS/FhipizKbF6e2bw8s3l5ZvPyzObVOKjZXFvPYgMAAMAMB/3SXwAAALgiQhUAAIBRhCoAAACjCFUAAABGEaoAAACMIlQBAAAYRagCAAAwyt8D947vi0b6vr8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot loss functions over epochs\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,7))\n",
    "\n",
    "\n",
    "ax1.plot(range(epochs), losses, c='r')\n",
    "ax1.plot(range(epochs), losses_test)\n",
    "ax1.set_title('Losses and epochs')\n",
    "\n",
    "ax2.plot(range(epochs), accuracy, c='r')\n",
    "ax2.plot(range(epochs), accuracy_test)\n",
    "ax2.set_title(\"Accuracy and epochs\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dictionary storing the data\n",
    "summary = {\n",
    "    \"Training\": [min(losses), max(accuracy)],\n",
    "    \"Test\": [min(losses_test), max(accuracy_test)]\n",
    "}\n",
    "\n",
    "# dataframe from dict\n",
    "summary_df = pd.DataFrame.from_dict(summary, orient='index', columns=['Loss', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy embeddings\n",
      "Model(\n",
      "  (embedding): Embedding(10529, 96)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=3840, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "  (out): Linear(in_features=1000, out_features=1, bias=True)\n",
      ")\n",
      "learning_rate:  0.001\n",
      "batch_size:  50\n",
      "time:  450.68721055984497\n"
     ]
    }
   ],
   "source": [
    "print('Spacy embeddings')\n",
    "print(model)\n",
    "print('learning_rate: ', learning_rate)\n",
    "print('batch_size: ', batch_size)\n",
    "print('time: ', duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cuda",
   "language": "python",
   "name": "torch-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
