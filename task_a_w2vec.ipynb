{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sprawdzanie czy w systemie jest karta graficzna Nvidia - CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_av = torch.cuda.is_available()\n",
    "cuda_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID urządzenia CUDA: 0\n",
      "Nazwa urządzenia CUDA: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "if cuda_av:\n",
    "    cuda_id = torch.cuda.current_device()\n",
    "    print(f'ID urządzenia CUDA: {cuda_id}')\n",
    "    print(f\"Nazwa urządzenia CUDA: {torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tworzenie kodu uniwersalnego: dla CUDA i CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ładowanie danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('data/olid-training-v1.0.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              tweet subtask_a  \\\n0  86426  @USER She should ask a few native Americans wh...       OFF   \n1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n2  16820  Amazon is investigating Chinese employees who ...       NOT   \n3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n\n  subtask_b subtask_c  \n0       UNT       NaN  \n1       TIN       IND  \n2       NaN       NaN  \n3       UNT       NaN  \n4       NaN       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>subtask_b</th>\n      <th>subtask_c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>86426</td>\n      <td>@USER She should ask a few native Americans wh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90194</td>\n      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16820</td>\n      <td>Amazon is investigating Chinese employees who ...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>62688</td>\n      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>43605</td>\n      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets = tweets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets = tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tokenizacja, lematyzacja, usówanie pewnych słów\n",
    "liczenie najdłuższego przetworzonego tweeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dodawanie kolumny z tokenami\n",
    "tweets['tokens'] = tweets['tweet'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              tweet subtask_a  \\\n0  86426  @USER She should ask a few native Americans wh...       OFF   \n1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n2  16820  Amazon is investigating Chinese employees who ...       NOT   \n3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n\n  subtask_b subtask_c                                             tokens  \n0       UNT       NaN  (@USER, She, should, ask, a, few, native, Amer...  \n1       TIN       IND  (@USER, @USER, Go, home, you, ’re, drunk, !, !...  \n2       NaN       NaN  (Amazon, is, investigating, Chinese, employees...  \n3       UNT       NaN  (@USER, Someone, should'veTaken, \", this, piec...  \n4       NaN       NaN  (@USER, @USER, Obama, wanted, liberals, &, amp...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>subtask_b</th>\n      <th>subtask_c</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>86426</td>\n      <td>@USER She should ask a few native Americans wh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, She, should, ask, a, few, native, Amer...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90194</td>\n      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, @USER, Go, home, you, ’re, drunk, !, !...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16820</td>\n      <td>Amazon is investigating Chinese employees who ...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(Amazon, is, investigating, Chinese, employees...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>62688</td>\n      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, Someone, should'veTaken, \", this, piec...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>43605</td>\n      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(@USER, @USER, Obama, wanted, liberals, &amp;, amp...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dodawanie kolumny z lematami za pomoca funkcji lambda - przy tym usuwanie:\n",
    "# odwolan do wczesniejszych tweetow (zawiera @)\n",
    "# - slowa url (czyli adresy stron inernetowych które w danych wejściowych mają URL zamiast adreasu.\n",
    "# # - hasztagów; przyimków i innych częstych słów (stop words) oraz znaków interpunkcyjnych.\n",
    "# spacji ' ', '  ', '   '\n",
    "\n",
    "# emotikony zostawiam - uważam, że też niosą znaczenie\n",
    "\n",
    "tweets['lemmas'] = tweets['tokens'].apply\\\n",
    "    (lambda list_tokens : [token.lemma_.strip() for token in list_tokens if ('@' not in token.lemma_ \\\n",
    "                                                                     and '#' not in token.lemma_ and 'url' not in token.lemma_ \\\n",
    "                                                                     and not token.is_stop and not token.is_punct and token.lemma_ != ' ' \\\n",
    "                                                                     and token.lemma_ != '  ' and token.lemma_ != '   '\n",
    "                                                                     and token.lemma_ != '    ' and token.lemma_.strip() != '')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              tweet subtask_a  \\\n0  86426  @USER She should ask a few native Americans wh...       OFF   \n1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n2  16820  Amazon is investigating Chinese employees who ...       NOT   \n3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n\n  subtask_b subtask_c                                             tokens  \\\n0       UNT       NaN  (@USER, She, should, ask, a, few, native, Amer...   \n1       TIN       IND  (@USER, @USER, Go, home, you, ’re, drunk, !, !...   \n2       NaN       NaN  (Amazon, is, investigating, Chinese, employees...   \n3       UNT       NaN  (@USER, Someone, should'veTaken, \", this, piec...   \n4       NaN       NaN  (@USER, @USER, Obama, wanted, liberals, &, amp...   \n\n                                              lemmas  length_lemmas  \\\n0                           [ask, native, Americans]              3   \n1         [home, drunk, MAGA, Trump2020, 👊, 🇺, 🇸, 👊]              8   \n2  [Amazon, investigate, chinese, employee, sell,...             18   \n3          [should'vetaken, piece, shit, volcano, 😂]              5   \n4   [Obama, want, liberal, amp, illegal, red, state]              7   \n\n                                             numbers  labels_a  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>subtask_b</th>\n      <th>subtask_c</th>\n      <th>tokens</th>\n      <th>lemmas</th>\n      <th>length_lemmas</th>\n      <th>numbers</th>\n      <th>labels_a</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>86426</td>\n      <td>@USER She should ask a few native Americans wh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, She, should, ask, a, few, native, Amer...</td>\n      <td>[ask, native, Americans]</td>\n      <td>3</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90194</td>\n      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, @USER, Go, home, you, ’re, drunk, !, !...</td>\n      <td>[home, drunk, MAGA, Trump2020, 👊, 🇺, 🇸, 👊]</td>\n      <td>8</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16820</td>\n      <td>Amazon is investigating Chinese employees who ...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(Amazon, is, investigating, Chinese, employees...</td>\n      <td>[Amazon, investigate, chinese, employee, sell,...</td>\n      <td>18</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>62688</td>\n      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, Someone, should'veTaken, \", this, piec...</td>\n      <td>[should'vetaken, piece, shit, volcano, 😂]</td>\n      <td>5</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>43605</td>\n      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(@USER, @USER, Obama, wanted, liberals, &amp;, amp...</td>\n      <td>[Obama, want, liberal, amp, illegal, red, state]</td>\n      <td>7</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for index, row in tweets.iterrows():\n",
    "#     for word in row['lemmas']:\n",
    "#         if word == '':\n",
    "#             print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets.iloc[499, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if tweets.iloc[500, 6][0] == '':\n",
    "#     print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets.iloc[500, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets.loc[:3,'lemmas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "@USER What’s the difference between #Kavanaugh and @USER   One of these men admitted to groping a 15 year old girl years ago.  The other is going to be #confirmed to the SCJ   #DemsareFrauds #DemsAreDone   #WalkAwayDemocrats2018 #redwave #VoteRedSaveAmerica #trumptrain #MAGA URL"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[11, 'tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets['length_lemmas'] = tweets['lemmas'].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0      3\n1      8\n2     18\n3      5\n4      7\n5      2\n6      4\n7     16\n8      2\n9     10\n10     4\nName: length_lemmas, dtype: int64"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[:10, 'length_lemmas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_length_tweet = max(tweets['length_lemmas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ładowanie danych testowych(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_level_a = pd.read_csv('data/testset-levela.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels_level_a = pd.read_csv('data/labels-levela.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels_level_a = labels_level_a.rename(columns={0:'id', 1:'subtask_a'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_a = pd.merge(test_level_a, labels_level_a, on = \"id\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              tweet subtask_a  \\\n0  15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       OFF   \n1  27014  #ConstitutionDay is revered by Conservatives, ...       NOT   \n2  30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...       NOT   \n3  13876  #Watching #Boomer getting the news that she is...       NOT   \n4  60133  #NoPasaran: Unity demo to oppose the far-right...       OFF   \n\n                                              tokens  \\\n0  (#, WhoIsQ, #, WheresTheServer, #, DumpNike, #...   \n1  (#, ConstitutionDay, is, revered, by, Conserva...   \n2  (#, FOXNews, #, NRA, #, MAGA, #, POTUS, #, TRU...   \n3  (#, Watching, #, Boomer, getting, the, news, t...   \n4  (#, NoPasaran, :, Unity, demo, to, oppose, the...   \n\n                                              lemmas  length_lemmas  \\\n0  [WhoIsQ, wherestheserver, DumpNike, DECLASFISA...             24   \n1  [ConstitutionDay, revere, conservative, hate, ...              9   \n2  [foxnew, NRA, MAGA, POTUS, TRUMP, 2ndamendment...             15   \n3  [watch, Boomer, get, news, parole, make, smile...             10   \n4  [NoPasaran, unity, demo, oppose, far, right, L...              9   \n\n                                             numbers  labels_a  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>tokens</th>\n      <th>lemmas</th>\n      <th>length_lemmas</th>\n      <th>numbers</th>\n      <th>labels_a</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15923</td>\n      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n      <td>OFF</td>\n      <td>(#, WhoIsQ, #, WheresTheServer, #, DumpNike, #...</td>\n      <td>[WhoIsQ, wherestheserver, DumpNike, DECLASFISA...</td>\n      <td>24</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>27014</td>\n      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n      <td>NOT</td>\n      <td>(#, ConstitutionDay, is, revered, by, Conserva...</td>\n      <td>[ConstitutionDay, revere, conservative, hate, ...</td>\n      <td>9</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30530</td>\n      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n      <td>NOT</td>\n      <td>(#, FOXNews, #, NRA, #, MAGA, #, POTUS, #, TRU...</td>\n      <td>[foxnew, NRA, MAGA, POTUS, TRUMP, 2ndamendment...</td>\n      <td>15</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13876</td>\n      <td>#Watching #Boomer getting the news that she is...</td>\n      <td>NOT</td>\n      <td>(#, Watching, #, Boomer, getting, the, news, t...</td>\n      <td>[watch, Boomer, get, news, parole, make, smile...</td>\n      <td>10</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60133</td>\n      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n      <td>OFF</td>\n      <td>(#, NoPasaran, :, Unity, demo, to, oppose, the...</td>\n      <td>[NoPasaran, unity, demo, oppose, far, right, L...</td>\n      <td>9</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "860"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "  subtask_a  labels_a\n0       OFF         1\n2       NOT         0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subtask_a</th>\n      <th>labels_a</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OFF</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NOT</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sprawdzanie czy etykiety są tak samo przydzielone liczbom w danych testowych i treningowych\n",
    "tweets.loc[[0, 2], ['subtask_a', 'labels_a']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "  subtask_a  labels_a\n0       OFF         1\n1       NOT         0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subtask_a</th>\n      <th>labels_a</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OFF</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NOT</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a.loc[[0, 1], ['subtask_a', 'labels_a']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opracowanie danych testowych (część a)\n",
    "Takie same modyfikacje jak dla danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_a['tokens'] = test_a['tweet'].apply(nlp)\n",
    "test_a['lemmas'] = test_a['tokens'].apply \\\n",
    "    (lambda list_tokens : [token.lemma_.strip() for token in list_tokens if ('@' not in token.lemma_\n",
    "                                                                             and '#' not in token.lemma_ and 'url' not in token.lemma_\n",
    "                                                                             and not token.is_stop and not token.is_punct and token.lemma_ != ' '\n",
    "                                                                             and token.lemma_ != '  ' and token.lemma_ != '   '\n",
    "                                                                             and token.lemma_ != '    ' and token.lemma_.strip() != '')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_a['length_lemmas'] = test_a['lemmas'].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "40"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_a['length_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              tweet subtask_a  \\\n0  15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       OFF   \n1  27014  #ConstitutionDay is revered by Conservatives, ...       NOT   \n2  30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...       NOT   \n3  13876  #Watching #Boomer getting the news that she is...       NOT   \n4  60133  #NoPasaran: Unity demo to oppose the far-right...       OFF   \n\n                                              tokens  \\\n0  (#, WhoIsQ, #, WheresTheServer, #, DumpNike, #...   \n1  (#, ConstitutionDay, is, revered, by, Conserva...   \n2  (#, FOXNews, #, NRA, #, MAGA, #, POTUS, #, TRU...   \n3  (#, Watching, #, Boomer, getting, the, news, t...   \n4  (#, NoPasaran, :, Unity, demo, to, oppose, the...   \n\n                                              lemmas  length_lemmas  \n0  [WhoIsQ, wherestheserver, DumpNike, DECLASFISA...             24  \n1  [ConstitutionDay, revere, conservative, hate, ...              9  \n2  [foxnew, NRA, MAGA, POTUS, TRUMP, 2ndamendment...             15  \n3  [watch, Boomer, get, news, parole, make, smile...             10  \n4  [NoPasaran, unity, demo, oppose, far, right, L...              9  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>tokens</th>\n      <th>lemmas</th>\n      <th>length_lemmas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15923</td>\n      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n      <td>OFF</td>\n      <td>(#, WhoIsQ, #, WheresTheServer, #, DumpNike, #...</td>\n      <td>[WhoIsQ, wherestheserver, DumpNike, DECLASFISA...</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>27014</td>\n      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n      <td>NOT</td>\n      <td>(#, ConstitutionDay, is, revered, by, Conserva...</td>\n      <td>[ConstitutionDay, revere, conservative, hate, ...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30530</td>\n      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n      <td>NOT</td>\n      <td>(#, FOXNews, #, NRA, #, MAGA, #, POTUS, #, TRU...</td>\n      <td>[foxnew, NRA, MAGA, POTUS, TRUMP, 2ndamendment...</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13876</td>\n      <td>#Watching #Boomer getting the news that she is...</td>\n      <td>NOT</td>\n      <td>(#, Watching, #, Boomer, getting, the, news, t...</td>\n      <td>[watch, Boomer, get, news, parole, make, smile...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60133</td>\n      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n      <td>OFF</td>\n      <td>(#, NoPasaran, :, Unity, demo, to, oppose, the...</td>\n      <td>[NoPasaran, unity, demo, oppose, far, right, L...</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "860"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_length_tweet_test = max(test_a['length_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "40"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_tweet_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Maksymalna długość wektora z lematami z tweetów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_width = max(max_length_tweet, max_length_tweet_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Funkcje do przekszałcania danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_words_to_numbers(lemmas_series, dict_ = dict()):\n",
    "    # dict_ = dict()\n",
    "    for row in lemmas_series:\n",
    "        for lemma in row:\n",
    "            if lemma not in dict_:\n",
    "                dict_[lemma] = len(dict_) + 1\n",
    "\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lemmas_to_numbers(row, max_list_lemmas, dict_):\n",
    "    list_numbers = []\n",
    "    for i in range(max_list_lemmas - len(row)):\n",
    "        list_numbers.append(0)\n",
    "\n",
    "    for lemma in row:\n",
    "        list_numbers.append(dict_[lemma])\n",
    "\n",
    "    array_numbers = np.array(list_numbers, dtype=np.int32)\n",
    "    return array_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Powrót do opracowywania danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_lemmas = convert_words_to_numbers(tweets['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['$',\n '&amp',\n \"'cause\",\n \"'em\",\n '(sorry',\n '*disclaimer',\n '+',\n '+15',\n '+2',\n '--&gt']"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict_lemmas)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# zamiana lematu na liczbe ze slownika ktory odpowiada danemu slowu\n",
    "tweets['numbers'] = tweets['lemmas'].apply(lambda row : lemmas_to_numbers(row, max_width, dict_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\nName: numbers, dtype: object"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['numbers'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# przypisywanie X_train kolumny numbers skonwertowanej na tablice numpy\n",
    "X_train = tweets['numbers'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# łączenie wierszy tablic w jedną tablicę 2D\n",
    "X_train = np.stack(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# konwertowanie tablicy 2d do tensora\n",
    "X_train = torch.FloatTensor(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ustawianie kolumn z etykietami na poszczególne zadania jako type które przechowują kategorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = ['subtask_a', 'subtask_b', 'subtask_c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    tweets[col] = tweets[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets['labels_a'] = tweets['subtask_a'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    1\n1    1\n2    0\n3    1\n4    0\n5    1\nName: labels_a, dtype: int8"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OFFENSIVE jest jako 1, a NOT OFFENSIVE jest jako 0\n",
    "tweets.loc[:5, 'labels_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          id                                              tweet subtask_a  \\\n0      86426  @USER She should ask a few native Americans wh...       OFF   \n1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n2      16820  Amazon is investigating Chinese employees who ...       NOT   \n3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n...      ...                                                ...       ...   \n13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n13236  67210  Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...       NOT   \n13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n13238  27429                                        @USER Pussy       OFF   \n13239  46552  #Spanishrevenge vs. #justice #HumanRights and ...       NOT   \n\n      subtask_b subtask_c                                             tokens  \\\n0           UNT       NaN  (@USER, She, should, ask, a, few, native, Amer...   \n1           TIN       IND  (@USER, @USER, Go, home, you, ’re, drunk, !, !...   \n2           NaN       NaN  (Amazon, is, investigating, Chinese, employees...   \n3           UNT       NaN  (@USER, Someone, should'veTaken, \", this, piec...   \n4           NaN       NaN  (@USER, @USER, Obama, wanted, liberals, &, amp...   \n...         ...       ...                                                ...   \n13235       TIN       IND  (@USER, Sometimes, I, get, strong, vibes, from...   \n13236       NaN       NaN  (Benidorm, ✅,  , Creamfields, ✅,  , Maga, ✅,  ...   \n13237       TIN       OTH  (@USER, And, why, report, this, garbage, .,  ,...   \n13238       UNT       NaN                                     (@USER, Pussy)   \n13239       NaN       NaN  (#, Spanishrevenge, vs., #, justice, #, HumanR...   \n\n                                                  lemmas  length_lemmas  \\\n0                               [ask, native, Americans]              3   \n1             [home, drunk, MAGA, Trump2020, 👊, 🇺, 🇸, 👊]              8   \n2      [Amazon, investigate, chinese, employee, sell,...             18   \n3              [should'vetaken, piece, shit, volcano, 😂]              5   \n4       [Obama, want, liberal, amp, illegal, red, state]              7   \n...                                                  ...            ...   \n13235  [strong, vibe, people, man, vibe, ten, million...             10   \n13236  [benidorm, ✅, creamfield, ✅, Maga, ✅, shabby, ...              8   \n13237                            [report, garbage, crap]              3   \n13238                                            [Pussy]              1   \n13239  [Spanishrevenge, vs., justice, HumanRights, fr...             10   \n\n                                                 numbers  labels_a  \n0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n...                                                  ...       ...  \n13235  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n13236  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n13237  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n13238  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n13239  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n\n[13240 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>subtask_b</th>\n      <th>subtask_c</th>\n      <th>tokens</th>\n      <th>lemmas</th>\n      <th>length_lemmas</th>\n      <th>numbers</th>\n      <th>labels_a</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>86426</td>\n      <td>@USER She should ask a few native Americans wh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, She, should, ask, a, few, native, Amer...</td>\n      <td>[ask, native, Americans]</td>\n      <td>3</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90194</td>\n      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, @USER, Go, home, you, ’re, drunk, !, !...</td>\n      <td>[home, drunk, MAGA, Trump2020, 👊, 🇺, 🇸, 👊]</td>\n      <td>8</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16820</td>\n      <td>Amazon is investigating Chinese employees who ...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(Amazon, is, investigating, Chinese, employees...</td>\n      <td>[Amazon, investigate, chinese, employee, sell,...</td>\n      <td>18</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>62688</td>\n      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, Someone, should'veTaken, \", this, piec...</td>\n      <td>[should'vetaken, piece, shit, volcano, 😂]</td>\n      <td>5</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>43605</td>\n      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(@USER, @USER, Obama, wanted, liberals, &amp;, amp...</td>\n      <td>[Obama, want, liberal, amp, illegal, red, state]</td>\n      <td>7</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13235</th>\n      <td>95338</td>\n      <td>@USER Sometimes I get strong vibes from people...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, Sometimes, I, get, strong, vibes, from...</td>\n      <td>[strong, vibe, people, man, vibe, ten, million...</td>\n      <td>10</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13236</th>\n      <td>67210</td>\n      <td>Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(Benidorm, ✅,  , Creamfields, ✅,  , Maga, ✅,  ...</td>\n      <td>[benidorm, ✅, creamfield, ✅, Maga, ✅, shabby, ...</td>\n      <td>8</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13237</th>\n      <td>82921</td>\n      <td>@USER And why report this garbage.  We don't g...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>OTH</td>\n      <td>(@USER, And, why, report, this, garbage, .,  ,...</td>\n      <td>[report, garbage, crap]</td>\n      <td>3</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13238</th>\n      <td>27429</td>\n      <td>@USER Pussy</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, Pussy)</td>\n      <td>[Pussy]</td>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13239</th>\n      <td>46552</td>\n      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(#, Spanishrevenge, vs., #, justice, #, HumanR...</td>\n      <td>[Spanishrevenge, vs., justice, HumanRights, fr...</td>\n      <td>10</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>13240 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "id                                                           86426\ntweet            @USER She should ask a few native Americans wh...\nsubtask_a                                                      OFF\nsubtask_b                                                      UNT\nsubtask_c                                                      NaN\ntokens           (@USER, She, should, ask, a, few, native, Amer...\nlemmas                                    [ask, native, Americans]\nlength_lemmas                                                    3\nnumbers          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\nlabels_a                                                         1\nName: 0, dtype: object"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train = tweets['labels_a'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1],\n        [1],\n        [0],\n        [1],\n        [0]], dtype=torch.int8)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = torch.cat((X_train, y_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Opracowywanie danych testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_lemmas = convert_words_to_numbers(test_a['lemmas'], dict_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['$',\n '&amp',\n \"'cause\",\n \"'em\",\n '(sorry',\n '*disclaimer',\n '+',\n '+15',\n '+2',\n '--&gt']"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict_lemmas)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# zamiana lematu na liczbe ze slownika ktory odpowiada danemu slowu\n",
    "test_a['numbers'] = test_a['lemmas'].apply(lambda row : lemmas_to_numbers(row, max_width, dict_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    [WhoIsQ, wherestheserver, DumpNike, DECLASFISA...\n1    [ConstitutionDay, revere, conservative, hate, ...\n2    [foxnew, NRA, MAGA, POTUS, TRUMP, 2ndamendment...\n3    [watch, Boomer, get, news, parole, make, smile...\n4    [NoPasaran, unity, demo, oppose, far, right, L...\nName: lemmas, dtype: object"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a['lemmas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n5    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\nName: numbers, dtype: object"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a.loc[:5, 'numbers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Robienie tego samego procesu co wcześniej dla danych testowych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test = test_a['numbers'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cat_cols = ['subtask_a', 'subtask_b', 'subtask_c']\n",
    "# for col in cat_cols:\n",
    "#     X_test[col] = X_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_a['subtask_a'] = test_a['subtask_a'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_a['labels_a'] = test_a['subtask_a'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    1\n1    0\n2    0\n3    0\n4    1\n5    1\nName: labels_a, dtype: int8"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OFFENSIVE jest jako 1, a NOT OFFENSIVE jest jako 0\n",
    "test_a.loc[:5, 'labels_a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test = test_a['labels_a'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test = torch.tensor(y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1],\n        [0],\n        [0],\n        [0],\n        [1]], dtype=torch.int8)"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_test_a = torch.cat((X_test, y_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_test_a = data_test_a.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generowanie embedingów na podstawie embedingów ze spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings.append(np.zeros(96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key, value in dict_lemmas.items():\n",
    "    embeddings.append(nlp(key)[0].vector)\n",
    "    # print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "21584"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_lemmas_inverted = {v: k for k, v in dict_lemmas.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dict_lemmas_inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_20468/3209827300.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# sprawdzanie embeddingów - czy się dobrze zapisały\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdict_lemmas\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mcomparison\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0membeddings\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mnlp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvector\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcomparison\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'false'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/spacy/language.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, text, disable, component_cfg)\u001B[0m\n\u001B[1;32m    998\u001B[0m                 \u001B[0merror_handler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mproc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_error_handler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    999\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1000\u001B[0;31m                 \u001B[0mdoc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mproc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcomponent_cfg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1001\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1002\u001B[0m                 \u001B[0;31m# This typically happens if a component is not initialized\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/spacy/pipeline/trainable_pipe.pyx\u001B[0m in \u001B[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/spacy/pipeline/tok2vec.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, docs)\u001B[0m\n\u001B[1;32m    119\u001B[0m         \u001B[0mDOCS\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mhttps\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m//\u001B[0m\u001B[0mspacy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mio\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mapi\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mtok2vec\u001B[0m\u001B[0;31m#predict\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    120\u001B[0m         \"\"\"\n\u001B[0;32m--> 121\u001B[0;31m         \u001B[0mtokvecs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    122\u001B[0m         \u001B[0mbatch_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTok2VecListener\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_batch_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    123\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mlistener\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlisteners\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/model.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0monly\u001B[0m \u001B[0mthe\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minstead\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    314\u001B[0m         \"\"\"\n\u001B[0;32m--> 315\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    316\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    317\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfinish_update\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptimizer\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/layers/chain.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0mcallbacks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         \u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minc_layer_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m         \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minc_layer_grad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/model.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    289\u001B[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001B[1;32m    290\u001B[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001B[0;32m--> 291\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    292\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minitialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mInT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mOutT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;34m\"Model\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/layers/with_array.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(model, Xseq, is_train)\u001B[0m\n\u001B[1;32m     38\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mXseq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_list_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mModel\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mList2d\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mList2d\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mXseq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/layers/with_array.py\u001B[0m in \u001B[0;36m_list_forward\u001B[0;34m(model, Xs, is_train)\u001B[0m\n\u001B[1;32m     74\u001B[0m     \u001B[0mlengths\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray1i\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseq\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mseq\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mXs\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m     \u001B[0mXf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mXs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpad\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpad\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 76\u001B[0;31m     \u001B[0mYf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mget_dXf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mXf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     77\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mbackprop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdYs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mList2d\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mList2d\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/model.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    289\u001B[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001B[1;32m    290\u001B[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001B[0;32m--> 291\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    292\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minitialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mInT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mOutT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;34m\"Model\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/layers/chain.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0mcallbacks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         \u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minc_layer_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m         \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minc_layer_grad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/model.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    289\u001B[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001B[1;32m    290\u001B[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001B[0;32m--> 291\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    292\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minitialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mInT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mOutT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;34m\"Model\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/layers/residual.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     38\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0md_output\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mdX\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m     \u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbackprop_layer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbackprop\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/model.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    289\u001B[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001B[1;32m    290\u001B[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001B[0;32m--> 291\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    292\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minitialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mInT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mOutT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;34m\"Model\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/layers/chain.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0mcallbacks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         \u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minc_layer_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m         \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minc_layer_grad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/model.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    289\u001B[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001B[1;32m    290\u001B[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001B[0;32m--> 291\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    292\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minitialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mInT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mOutT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;34m\"Model\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/layers/chain.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0mcallbacks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         \u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minc_layer_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m         \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minc_layer_grad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/model.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    289\u001B[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001B[1;32m    290\u001B[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001B[0;32m--> 291\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    292\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minitialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mInT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mOutT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;34m\"Model\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/layers/chain.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0mcallbacks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         \u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minc_layer_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m         \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minc_layer_grad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/model.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    289\u001B[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001B[1;32m    290\u001B[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001B[0;32m--> 291\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    292\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minitialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mInT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mOutT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;34m\"Model\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/layers/layernorm.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mModel\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mInT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mInT\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mInT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTuple\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mInT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mCallable\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m     \u001B[0mN\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmu\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvar\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_moments\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mops\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m     \u001B[0mXhat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mmu\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mvar\u001B[0m \u001B[0;34m**\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1.0\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;36m2.0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbackprop_rescale\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_begin_update_scale_shift\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mXhat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/thinc/layers/layernorm.py\u001B[0m in \u001B[0;36m_get_moments\u001B[0;34m(ops, X)\u001B[0m\n\u001B[1;32m     75\u001B[0m     \u001B[0;31m# TODO: Do mean methods\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m     \u001B[0mmu\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mFloats2d\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 77\u001B[0;31m     \u001B[0mvar\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mFloats2d\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1e-08\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     78\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mFloats2d\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray_f\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmu\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvar\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/extra/miniconda/envs/torch/lib/python3.9/site-packages/numpy/core/_methods.py\u001B[0m in \u001B[0;36m_var\u001B[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001B[0m\n\u001B[1;32m    227\u001B[0m     \u001B[0;31m# Note that x may not be inexact and that we need it to be an array,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m     \u001B[0;31m# not a scalar.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 229\u001B[0;31m     \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0masanyarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0marrmean\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    230\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    231\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0missubclass\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mnt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloating\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minteger\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# sprawdzanie embeddingów - czy się dobrze zapisały\n",
    "for key, value in dict_lemmas.items():\n",
    "    comparison = embeddings[value] == nlp(key)[0].vector\n",
    "    if comparison.all() == False:\n",
    "        print('false')\n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emb_torch = torch.tensor(embeddings, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emb_torch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, emb_vectors, in_features=18, h1=80, h2=50, h3=None, embedding_dim=None, out_features=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # warstwa embeddingów\n",
    "        self.embedding = nn.Embedding.from_pretrained(emb_vectors)\n",
    "\n",
    "        # self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # dropout layer - losowe pomijanie uczenia się pewnych neuronów\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc1 = nn.Linear(embedding_dim * in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        if h3 is None:\n",
    "            self.out = nn.Linear(h2, out_features)\n",
    "        # self.sig = nn.Sigmoid()\n",
    "        else:\n",
    "            self.fc3 = nn.Linear(h2, h3)\n",
    "            self.out = nn.Linear(h3, out_features)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = x.long()\n",
    "        # print(x.shape)\n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "        # print(embeds.shape)\n",
    "        embeds = embeds.view(embeds.shape[0], -1)\n",
    "        # print(embeds.shape)\n",
    "        x = torch.sigmoid(self.fc1(embeds))\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        if h3 is not None:\n",
    "            x = torch.sigmoid(self.fc3(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ustawnia modelu i sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('max width: 73')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 500\n",
    "vocab_size = len(dict_lemmas) + 1\n",
    "embedding_dim = emb_torch.shape[1]\n",
    "h1 = 100\n",
    "h2 = 100\n",
    "h3 = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "test_dataset_loader_a = torch.utils.data.DataLoader(data_test_a, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tworzenie instancji modelu\n",
    "Ustawianie funkcji straty i optymalizatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tworzenie numpy array z listy liczb (odpowiadających lematom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(32)\n",
    "model = Model(emb_torch, max_width, h1, h2, h3, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ustawianie nauki sieci i samo uczenie się"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "losses_test = []\n",
    "accuracy = []\n",
    "accuracy_test = []\n",
    "train_count = len(tweets)\n",
    "test_count_a = len(test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for e in range(epochs):\n",
    "    loss_epoch = torch.empty(0)\n",
    "    correct_epoch = 0\n",
    "\n",
    "    loss_epoch_test = np.empty(0)\n",
    "    correct_epoch_test = 0\n",
    "\n",
    "    for batch_num, batch in enumerate(train_dataset_loader):\n",
    "        X_train = batch[:,:-1]\n",
    "        y_train = batch[:,-1].reshape(-1,1)\n",
    "        y_pred = model.forward(X_train)\n",
    "\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        if (e == 0 and batch_num == 0):\n",
    "            print(f'Loss on the first batch: {loss}')\n",
    "\n",
    "        # print(loss.item())\n",
    "        loss_epoch = np.append(loss_epoch, loss.detach().cpu().numpy())\n",
    "        # losses.append(loss.item())\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        predicted = torch.round(y_pred)\n",
    "        # print(y_train)\n",
    "        predicted = (predicted == y_train).sum().cpu()\n",
    "        pred_cpu = predicted.cpu()\n",
    "        # print(f'pred_cpu: {pred_cpu}')\n",
    "        correct_epoch += predicted\n",
    "\n",
    "# przechodzenie przez dane testowe\n",
    "    with torch.no_grad():\n",
    "        for batch_num_test, batch_test in enumerate(test_dataset_loader_a):\n",
    "            X_test = batch_test[:,:-1]\n",
    "            y_test = batch_test[:,-1].reshape(-1,1)\n",
    "            y_pred_test = model.forward(X_test)\n",
    "\n",
    "            loss_test = criterion(y_pred_test, y_test)\n",
    "            if (e == 0 and batch_num_test == 0):\n",
    "                print(f'Loss on the first batch on test data: {loss_test}')\n",
    "                print(loss_test.shape)\n",
    "\n",
    "            # print(loss.item())\n",
    "            loss_epoch_test = np.append(loss_epoch_test, loss_test.item())\n",
    "            # print(loss_test)\n",
    "            # losses.append(loss.item())\n",
    "\n",
    "            predicted = torch.round(y_pred_test)\n",
    "            # print(predicted)\n",
    "            # print(y_test)\n",
    "            predicted = (predicted == y_test).sum()\n",
    "            pred_cpu = predicted.cpu()\n",
    "            # print(f'pred_cpu: {pred_cpu}')\n",
    "            correct_epoch_test += predicted\n",
    "\n",
    "        loss_epoch_test = loss_epoch_test.sum() / test_count_a\n",
    "        losses_test.append(loss_epoch_test)\n",
    "        accuracy_epoch_test = correct_epoch_test * 100/test_count_a\n",
    "        accuracy_epoch_test_cpu = accuracy_epoch_test.cpu()\n",
    "        accuracy_test.append(accuracy_epoch_test_cpu)\n",
    "\n",
    "    loss_epoch = loss_epoch.sum() / train_count\n",
    "    losses.append(loss_epoch)\n",
    "    accuracy_epoch = correct_epoch * 100/train_count\n",
    "    accuracy_epoch_cpu = accuracy_epoch.cpu()\n",
    "    accuracy.append(accuracy_epoch)\n",
    "\n",
    "\n",
    "    # print(f'Test accuracy: {correct_epoch.item()}/{train_count} = {correct.item() * 100 / (test_count):7.3f}%')\n",
    "    print(f' epoch: {e} | loss: {loss_epoch} | predicted: {correct_epoch} | accuracy: {accuracy_epoch} | test loss: {loss_epoch_test} | ' \\\n",
    "          + f'predicted: {correct_epoch_test} | test accuracy: {accuracy_epoch_test}')\n",
    "\n",
    "duration = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Rysowanie funkcji straty i accuracy na przestrzeni epok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Plot loss functions over epochs\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,7))\n",
    "\n",
    "\n",
    "ax1.plot(range(epochs), losses, c='r')\n",
    "ax1.plot(range(epochs), losses_test)\n",
    "ax1.set_title('Losses and epochs')\n",
    "\n",
    "ax2.plot(range(epochs), accuracy, c='r')\n",
    "ax2.plot(range(epochs), accuracy_test)\n",
    "ax2.set_title(\"Accuracy and epochs\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dictionary storing the data\n",
    "summary = {\n",
    "    \"Training\": [min(losses), max(accuracy)],\n",
    "    \"Test\": [min(losses_test), max(accuracy_test)]\n",
    "}\n",
    "\n",
    "# dataframe from dict\n",
    "summary_df = pd.DataFrame.from_dict(summary, orient='index', columns=['Loss', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Spacy embeddings')\n",
    "print(model)\n",
    "print('learning_rate: ', learning_rate)\n",
    "print('batch_size: ', batch_size)\n",
    "print('time: ', duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cuda",
   "language": "python",
   "name": "torch-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}